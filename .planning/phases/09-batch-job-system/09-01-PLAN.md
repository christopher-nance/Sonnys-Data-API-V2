---
phase: 09-batch-job-system
plan: 01
type: tdd
---

<objective>
Add batch job support to the Transactions resource — submit a job via POST, poll for completion, and return parsed results.

Purpose: Implement the most complex API pattern (async job flow) as a single dead-simple method call, fulfilling the PROJECT.md requirement for "Auto-polling for batch job endpoints."
Output: Working `client.transactions.load_job(startDate=..., endDate=...)` that returns `list[TransactionJobItem]` — tested poll loop with pass/working/fail/timeout scenarios.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase research:
@.planning/phases/09-batch-job-system/09-RESEARCH.md

# Dependency graph — selected via frontmatter:
@.planning/phases/05-resource-framework/05-01-SUMMARY.md
@.planning/phases/08-transaction-resources/08-01-SUMMARY.md
@.planning/phases/08-transaction-resources/08-02-SUMMARY.md

# Key source files:
@src/sonnys_data_client/resources/_transactions.py
@src/sonnys_data_client/_client.py
@src/sonnys_data_client/_exceptions.py
@src/sonnys_data_client/types/_transactions.py
@tests/test_resources.py

**Tech stack available:** requests, pydantic v2, pytest, ListableResource/GettableResource mixins, _paginated_fetch helper, TransactionJobItem model, APITimeoutError/APIError exceptions
**Established patterns:**
- _request(method, path, *, params) as single HTTP pipeline with rate limiting and 429 retry (03-02)
- _paginated_fetch for custom paginated endpoints on Transactions (08-01)
- time.monotonic for timing (03-01)
- Mock responses via requests.models.Response with _content injection (02-02, 05-01)
- Mock _request with MagicMock side_effect for multi-call sequences (05-01)
- unittest.mock.patch for time.sleep and time.monotonic (03-02)

**Constraining decisions:**
- Phase 03: time.monotonic over time.time — immune to clock drift
- Phase 05: Resource mixin pattern — custom methods added directly to resource class
- Phase 08: _paginated_fetch duplicated on Transactions for custom endpoints
- Research: POST for load-job (per OpenAPI spec), GET for get-job-data
- Research: get-job-data status enum: "pass", "working", "fail"
- Research: Hash cached 20 minutes, date range max 24 hours
- Research: Don't hand-roll rate limiting during polls — _request() handles it
- Research: Default poll_interval=2.0s to avoid rate limiter starvation
</context>

<feature>
  <name>Batch job load_job() with submit-poll-return</name>
  <files>src/sonnys_data_client/resources/_transactions.py, tests/test_batch_job.py</files>
  <behavior>
    **Submit job and get hash:**
    Given load_job(startDate=1591040159, endDate=1591126559)
    Then POST to /transaction/load-job with params={startDate: 1591040159, endDate: 1591126559}
    And extract hash from response.json()["data"]["hash"]

    **Immediate pass:**
    Given get-job-data returns status="pass" on first poll
    Then return list of TransactionJobItem parsed from response.json()["data"]["data"]

    **Working then pass:**
    Given get-job-data returns status="working" once, then status="pass"
    Then sleep(poll_interval) between polls
    And return parsed TransactionJobItem list when status="pass"

    **Job failure:**
    Given get-job-data returns status="fail"
    Then raise APIError("Batch job failed")

    **Poll timeout:**
    Given get-job-data keeps returning status="working" past the deadline
    Then raise APITimeoutError with message including timeout value

    **Data parsing:**
    Given get-job-data returns status="pass" with transaction objects
    Then each item is parsed through TransactionJobItem.model_validate()
    And returned as list[TransactionJobItem]

    **Poll interval and timeout are configurable:**
    load_job(poll_interval=1.0, timeout=60.0) uses those values instead of defaults
  </behavior>
  <implementation>
    Add `load_job()` method to the existing `Transactions` class in `resources/_transactions.py`.

    **Method signature:**
    ```python
    def load_job(
        self,
        *,
        poll_interval: float = 2.0,
        timeout: float = 300.0,
        **params: object,
    ) -> list[TransactionJobItem]:
    ```

    **Implementation steps:**
    1. `import time` at module level
    2. Import `APIError, APITimeoutError` from `sonnys_data_client._exceptions`
    3. Import `TransactionJobItem` from `sonnys_data_client.types._transactions`
    4. POST to `/transaction/load-job` via `self._client._request("POST", "/transaction/load-job", params=params)` — extract `hash` from `response.json()["data"]["hash"]`
    5. Calculate deadline: `deadline = time.monotonic() + timeout`
    6. Poll loop:
       - GET `/transaction/get-job-data` via `self._client._request("GET", "/transaction/get-job-data", params={"hash": hash_value})`
       - Parse `body = response.json()["data"]`, check `body["status"]`
       - If `"pass"`: return `[TransactionJobItem.model_validate(item) for item in body["data"]]`
       - If `"fail"`: raise `APIError("Batch job failed")`
       - If `"working"`: check `time.monotonic() >= deadline` → raise `APITimeoutError(f"Batch job did not complete within {timeout}s")`, else `time.sleep(poll_interval)` and continue

    **What to avoid and WHY:**
    - Do NOT add pagination to get-job-data — the spec only documents `hash` as a query param. If truncation is observed during integration testing, address it then. (Research open question #1)
    - Do NOT add new exception classes — APIError and APITimeoutError already exist and are semantically correct. Adding JobFailedError/JobTimeoutError is over-engineering for a single method.
    - Do NOT extract the poll loop to a utility — it's used once, on one resource. YAGNI.
    - Do NOT validate startDate/endDate or the 24-hour constraint in Python — let the API validate and return a ValidationError. (Same pattern as list_by_type not validating item_type)
    - Check timeout AFTER each poll attempt (not before sleeping) — ensures at least one poll happens even with timeout=0.

    **Test approach:**
    Create `tests/test_batch_job.py`. Reuse the mock response helper pattern from `tests/test_resources.py` (build `requests.Response` with `_content` injection). Mock `client._request` with `MagicMock(side_effect=[...])` for multi-call sequences. Patch `time.sleep` to prevent real sleeping. Patch `time.monotonic` to control deadline logic deterministically.
  </implementation>
</feature>

<verification>
python -m pytest tests/test_batch_job.py -v
All tests pass, no import errors.
python -c "from sonnys_data_client.resources._transactions import Transactions; t = type('C', (), {'_request': None})(); tr = Transactions(t); print(hasattr(tr, 'load_job'))"
</verification>

<success_criteria>
- Failing tests written and committed (RED)
- Implementation passes all tests (GREEN)
- Refactor complete if needed (REFACTOR)
- load_job() submits POST to /transaction/load-job and extracts hash
- Poll loop handles "pass" (return data), "fail" (raise APIError), "working" (sleep + retry)
- Timeout raises APITimeoutError after deadline exceeded
- time.sleep called with poll_interval between polls
- All 2-3 commits present
- Phase 9 complete (single plan phase)
</success_criteria>

<output>
After completion, create `.planning/phases/09-batch-job-system/09-01-SUMMARY.md`:

# Phase 9 Plan 1: Batch Job Load and Poll Summary

**[substantive one-liner]**

## Performance
- Duration, started, completed, files modified

## Accomplishments
- Key outcomes

## TDD Cycle

### RED - Failing Tests
### GREEN - Implementation
### REFACTOR

## Task Commits

## Files Created/Modified

## Decisions Made

## Deviations from Plan

## Issues Encountered

## Next Phase Readiness
- Phase 9 complete — Batch Job System implemented
- Ready for Phase 10: Packaging & Distribution
</output>
